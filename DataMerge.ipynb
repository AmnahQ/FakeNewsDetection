{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1LM3Bdf6gW9",
        "outputId": "7d5c5e2e-94a2-4eb4-efd7-835b89ee1019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (44898, 2)\n",
            "\n",
            "Class distribution:\n",
            "label\n",
            "0    23481\n",
            "1    21417\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentage distribution:\n",
            "label\n",
            "0    0.522985\n",
            "1    0.477015\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "First 5 rows:\n",
            "                                                text  label\n",
            "0  21st Century Wire says Ben Stein, reputable pr...      0\n",
            "1  WASHINGTON (Reuters) - U.S. President Donald T...      1\n",
            "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...      1\n",
            "3  On Monday, Donald Trump once again embarrassed...      0\n",
            "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...      1\n",
            "\n",
            "✅ Dataset saved as 'combined_news_dataset.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the two separate files\n",
        "fake_news = pd.read_csv('Fake.csv')  # Replace with your fake news filename\n",
        "true_news = pd.read_csv('True.csv')  # Replace with your true news filename\n",
        "\n",
        "# Add label column (0 for fake, 1 for true)\n",
        "fake_news['label'] = 0\n",
        "true_news['label'] = 1\n",
        "\n",
        "# Keep only 'text' and 'label' columns\n",
        "fake_news = fake_news[['text', 'label']]\n",
        "true_news = true_news[['text', 'label']]\n",
        "\n",
        "# Combine both datasets\n",
        "combined_df = pd.concat([fake_news, true_news], ignore_index=True)\n",
        "\n",
        "# Shuffle the dataset (important!)\n",
        "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Remove any missing values\n",
        "combined_df.dropna(inplace=True)\n",
        "\n",
        "# Check the distribution\n",
        "print(\"Dataset shape:\", combined_df.shape)\n",
        "print(\"\\nClass distribution:\")\n",
        "print(combined_df['label'].value_counts())\n",
        "print(\"\\nPercentage distribution:\")\n",
        "print(combined_df['label'].value_counts(normalize=True))\n",
        "\n",
        "# Display first few rows\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(combined_df.head())\n",
        "\n",
        "# Save to CSV\n",
        "combined_df.to_csv('combined_news_dataset.csv', index=False)\n",
        "print(\"\\n✅ Dataset saved as 'combined_news_dataset.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nfXK2dO3-NV5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}